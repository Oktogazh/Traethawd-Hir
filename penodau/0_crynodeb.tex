\abstract{This dissertation introduces leksis, a lexical decision task vocabulary test. The scoring mechanism is derived from the Elo rating system, used in chess, which works on the same principles as the Rasch model more common in psychometrics. Several versions of the tests were implemented so far, a Breton one first, then others for Welsh, French and Ukrainian. The goal of the dissertation is to measure the adaptivity the tests. It is admitted that the purpose of the test is to bring the test taker to the point where the chances of recognising a real word are exactly at 50\%, that is, perfectly uncertain. After a little more than two months, the results collected for the Breton test seem conclusive over several vocabulary level ranges. The ranges with the most collected data seem well calibrated, which seems to consolidate the idea that little calibration effort is needed to create a reliable test. The innovation making this feat possible is a method we dubbed ``bean'' or ``modulo'' clustering. This item rating initialisation technique effectively turn any fully adaptive Elo based test in a hybrid system between a proportion of correct answers based system and a logistic scale it is supposed to be in the first place, thus finding a trade-off between calibration of new items (scalability) and exploitation of known items (precision). The test also introduces the use of RNN (LSTM) in the making of pseudo-words, which appeared to be convincing, with a fifth of them being recognised as real words in average by the test takers. 
At the end of a session, the test creates a personalised analysis prompt that test takers can share with an LLM to generate an interactive language lessons based on the results. A tool whose pedagogical value is still to be assessed.}